{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee60b19",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf979ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold,cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from yellowbrick.classifier import ClassificationReport\n",
    "import warnings\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee81e0b",
   "metadata": {},
   "source": [
    "# Data preprocessing stage - merging and cleaning of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d21cb0",
   "metadata": {},
   "source": [
    "### Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1434f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all the required datasets - metabolomics dataset, drug response dataset and the metadata of the cell lines\n",
    "\n",
    "data = pd.read_excel(\"D:\\\\GaTech\\\\Fall Sem\\\\BIOL 8901\\\\Metabolomic Project\\\\metabolomic_data.xlsx\", sheet_name=\"1-clean data\")\n",
    "data.rename(columns = {'Unnamed: 0': 'ID'}, inplace = True)\n",
    "last_column = data.iloc[:,-1].name\n",
    "sample = pd.read_csv(\"D:\\\\GaTech\\\\Fall Sem\\\\BIOL 8901\\\\sample_info.csv\")\n",
    "sample.rename(columns = {'CCLE_Name':'ID'}, inplace=True)\n",
    "merged_data = data.merge(sample, on='ID')\n",
    "drug = pd.read_csv('D:\\\\GaTech\\\\Fall Sem\\\\BIOL 8901\\\\sanger-dose-response.csv')\n",
    "drug.rename(columns={'ARXSPAN_ID':'DepMap_ID'}, inplace = True)\n",
    "working_data = merged_data.merge(drug, on='DepMap_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09b1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since our data has a lot of NaN's in them, we can fill them using 0 (for now, just for a workaround)\n",
    "\n",
    "working_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af37777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = working_data.loc[working_data['DRUG_NAME'] == 'CISPLATIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba782515",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "reset the index as once we take a subset of the main working_dataset, the indexes will get mixed up.\n",
    "thus the indices need to be reset before we start working on the model\n",
    "'''\n",
    "\n",
    "X1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde154be",
   "metadata": {},
   "source": [
    "### Remove GDSC1 data (per GDSC instructions) and keep GDSC2 data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1d10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wherever there is any duplicate within a cell line's IC50 values, take the cell line that originates from the GDSC2 phase \n",
    "X_ = X1[~X1.duplicated(['DepMap_ID'], keep=False) | X1['DATASET'].eq('GDSC2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba12bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e9f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the metadata\n",
    "\n",
    "X_ = X_.select_dtypes('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666054ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e29bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the dataframe, at a quick glance the metabolite profiles are not scaled thus scaling of the dataframe is necessary\n",
    "\n",
    "X_min = X_.min()\n",
    "X_max = X_.max()\n",
    "X_range = (X_max-X_min)\n",
    "X_scaled = (X_-X_min)/(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959d5d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019814174656500174 0.07151777667799389\n"
     ]
    }
   ],
   "source": [
    "#calculate the mean and standard deviation of the IC50_PUBLISHED\n",
    "\n",
    "drug_mean = X_scaled['IC50_PUBLISHED'].mean()\n",
    "drug_std = X_scaled['IC50_PUBLISHED'].std()\n",
    "print(drug_mean, drug_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95c213",
   "metadata": {},
   "source": [
    "### Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f649a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels\n",
    "\n",
    "ic, labels = X_scaled['IC50_PUBLISHED'], []\n",
    "for i in range(len(ic)):\n",
    "    #if the IC50_PUBLISHED value is greater than the mean, add responsive label to the label list\n",
    "    if ic[i] > drug_mean+0.15*drug_std:\n",
    "        labels.append('R')\n",
    "    #if the IC50_PUBLISHED value is less than the mean, add non responsive label to the label list\n",
    "    elif ic[i] < drug_mean-0.15*drug_std:\n",
    "        labels.append('NR')\n",
    "    else:\n",
    "        labels.append('N')\n",
    "        \n",
    "y = pd.Series(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75cfc187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NR    454\n",
       "N      83\n",
       "R      81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f69f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_.iloc[:, :225]\n",
    "X.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de95cf4",
   "metadata": {},
   "source": [
    "### Dimension reduction using Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49bc1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the correlation matrix of the metabolite dataframe\n",
    "#choose the upper triangle of the correlation matrix\n",
    "#create a list of features where the correlation value is >0.90\n",
    "#this list contains the highly correlated features, which will be removed from the dataset\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column]>0.90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6eeb1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d9fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the list of highly correlated features computed above\n",
    "\n",
    "X.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4da9281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((618, 205), (618,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5abd215",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908a39b",
   "metadata": {},
   "source": [
    "### Feature Selection using Recursive Feature Elimination using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0026624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the RFECV model with estimator being Random Forest and StratifiedKFold cross validation with 5 folds.\n",
    "\n",
    "rfecv = RFECV(estimator = RandomForestClassifier(random_state=101), step=1, cv=StratifiedKFold(5), scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ddc7db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "      estimator=RandomForestClassifier(random_state=101), scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the X,y to the RFECV model\n",
    "\n",
    "rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24d2c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the features that are selected by the RFECV model\n",
    "\n",
    "selected_features = rfecv.get_support(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5747900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 178)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select a subset dataframe that contains only the \"optimal\" metabolic features returned from the RFECV model\n",
    "\n",
    "X3 = X[X.columns[selected_features]]\n",
    "X3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c46e2",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f1f8e",
   "metadata": {},
   "source": [
    "### Model training and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83361a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using classification_report metrics, run a prediction model using StratifiedKFold cross_validation with k=5 folds\n",
    "#model being used as the classifier is Random Forest\n",
    "\n",
    "kf3 = StratifiedKFold(n_splits = 5, shuffle=False)\n",
    "model=RandomForestClassifier()\n",
    "i=1\n",
    "dfs = []\n",
    "for train_index, test_index in kf3.split(X3, y):\n",
    "    #select train and test datasets from X and y\n",
    "    X_train, X_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    #predict the test dataset\n",
    "    predicted = model.predict(X_test)\n",
    "    #print the classification score report\n",
    "    report = classification_report(y_test, predicted, output_dict = True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    dfs.append(df)\n",
    "    i+=1\n",
    "results_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ccb8d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.244624</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.538567</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.621230</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.244624</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.538567</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.621230</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.244624</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282171</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.538567</td>\n",
       "      <td>0.733871</td>\n",
       "      <td>0.621230</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.739837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.739837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.246612</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.283489</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.547359</td>\n",
       "      <td>0.739837</td>\n",
       "      <td>0.629208</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.731707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.535396</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "N              0.000000  0.000000  0.000000   17.000000\n",
       "NR             0.733871  1.000000  0.846512   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.733871  0.733871  0.733871    0.733871\n",
       "macro avg      0.244624  0.333333  0.282171  124.000000\n",
       "weighted avg   0.538567  0.733871  0.621230  124.000000\n",
       "N              0.000000  0.000000  0.000000   17.000000\n",
       "NR             0.733871  1.000000  0.846512   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.733871  0.733871  0.733871    0.733871\n",
       "macro avg      0.244624  0.333333  0.282171  124.000000\n",
       "weighted avg   0.538567  0.733871  0.621230  124.000000\n",
       "N              0.000000  0.000000  0.000000   17.000000\n",
       "NR             0.733871  1.000000  0.846512   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.733871  0.733871  0.733871    0.733871\n",
       "macro avg      0.244624  0.333333  0.282171  124.000000\n",
       "weighted avg   0.538567  0.733871  0.621230  124.000000\n",
       "N              0.000000  0.000000  0.000000   16.000000\n",
       "NR             0.739837  1.000000  0.850467   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.739837  0.739837  0.739837    0.739837\n",
       "macro avg      0.246612  0.333333  0.283489  123.000000\n",
       "weighted avg   0.547359  0.739837  0.629208  123.000000\n",
       "N              0.000000  0.000000  0.000000   16.000000\n",
       "NR             0.731707  1.000000  0.845070   90.000000\n",
       "R              0.000000  0.000000  0.000000   17.000000\n",
       "accuracy       0.731707  0.731707  0.731707    0.731707\n",
       "macro avg      0.243902  0.333333  0.281690  123.000000\n",
       "weighted avg   0.535396  0.731707  0.618344  123.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4b01849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.to_csv(\"CISPLATIN_Results_RF.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615fbbc",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a99c6",
   "metadata": {},
   "source": [
    "### Model training and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d382611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using classification_report metrics, run a prediction model using StratifiedKFold cross_validation with k=5 folds\n",
    "#model being used as the classifier is Support Vector Machine\n",
    "\n",
    "kf5 = StratifiedKFold(n_splits = 5, shuffle=False)\n",
    "model2=svm.SVC(kernel='linear', C=100)\n",
    "i=1\n",
    "dfs_svm = []\n",
    "for train_index, test_index in kf5.split(X3, y):\n",
    "    #select train and test datasets from X and y\n",
    "    X_train, X_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #train the model\n",
    "    model2.fit(X_train, y_train)\n",
    "    #predict the test dataset\n",
    "    predicted2 = model2.predict(X_test)\n",
    "    #print the classification score report\n",
    "    report = classification_report(y_test, predicted2, output_dict = True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    dfs_svm.append(df)\n",
    "    i+=1\n",
    "results_df_svm = pd.concat(dfs_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b45b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.382377</td>\n",
       "      <td>0.385208</td>\n",
       "      <td>0.378322</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.622184</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.584510</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.385956</td>\n",
       "      <td>0.401153</td>\n",
       "      <td>0.389324</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.604784</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.577170</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>0.706587</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.370076</td>\n",
       "      <td>0.377882</td>\n",
       "      <td>0.367397</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.614091</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.571125</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.395398</td>\n",
       "      <td>0.401099</td>\n",
       "      <td>0.392904</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.648281</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.612439</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.626016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.462217</td>\n",
       "      <td>0.419771</td>\n",
       "      <td>0.405599</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.660781</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.628825</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "N              0.142857  0.235294  0.177778   17.000000\n",
       "NR             0.782051  0.670330  0.721893   91.000000\n",
       "R              0.222222  0.250000  0.235294   16.000000\n",
       "accuracy       0.556452  0.556452  0.556452    0.556452\n",
       "macro avg      0.382377  0.385208  0.378322  124.000000\n",
       "weighted avg   0.622184  0.556452  0.584510  124.000000\n",
       "N              0.217391  0.294118  0.250000   17.000000\n",
       "NR             0.750000  0.659341  0.701754   91.000000\n",
       "R              0.190476  0.250000  0.216216   16.000000\n",
       "accuracy       0.556452  0.556452  0.556452    0.556452\n",
       "macro avg      0.385956  0.401153  0.389324  124.000000\n",
       "weighted avg   0.604784  0.556452  0.577170  124.000000\n",
       "N              0.160000  0.235294  0.190476   17.000000\n",
       "NR             0.776316  0.648352  0.706587   91.000000\n",
       "R              0.173913  0.250000  0.205128   16.000000\n",
       "accuracy       0.540323  0.540323  0.540323    0.540323\n",
       "macro avg      0.370076  0.377882  0.367397  124.000000\n",
       "weighted avg   0.614091  0.540323  0.571125  124.000000\n",
       "N              0.153846  0.250000  0.190476   16.000000\n",
       "NR             0.810127  0.703297  0.752941   91.000000\n",
       "R              0.222222  0.250000  0.235294   16.000000\n",
       "accuracy       0.585366  0.585366  0.585366    0.585366\n",
       "macro avg      0.395398  0.401099  0.392904  123.000000\n",
       "weighted avg   0.648281  0.585366  0.612439  123.000000\n",
       "N              0.193548  0.375000  0.255319   16.000000\n",
       "NR             0.793103  0.766667  0.779661   90.000000\n",
       "R              0.400000  0.117647  0.181818   17.000000\n",
       "accuracy       0.626016  0.626016  0.626016    0.626016\n",
       "macro avg      0.462217  0.419771  0.405599  123.000000\n",
       "weighted avg   0.660781  0.626016  0.628825  123.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9814d",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5748a0",
   "metadata": {},
   "source": [
    "### Model training and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dff5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using classification_report metrics, run a prediction model using StratifiedKFold cross_validation with k=5 folds\n",
    "#model being used as the classifier is AdaBoost Algorithm\n",
    "\n",
    "kf5 = StratifiedKFold(n_splits = 5, shuffle=False)\n",
    "model3=AdaBoostClassifier(n_estimators=500, learning_rate=0.8)\n",
    "i=1\n",
    "dfs_adb = []\n",
    "for train_index, test_index in kf5.split(X3, y):\n",
    "    #select train and test datasets from X and y\n",
    "    X_train, X_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #train the model\n",
    "    model3.fit(X_train, y_train)\n",
    "    #predict the test dataset\n",
    "    predicted3 = model3.predict(X_test)\n",
    "    #print the classification score report\n",
    "    report = classification_report(y_test, predicted3, output_dict = True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    dfs_adb.append(df)\n",
    "    i+=1\n",
    "results_df_adb = pd.concat(dfs_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0527d06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.274194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.342681</td>\n",
       "      <td>0.363701</td>\n",
       "      <td>0.222533</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.581831</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.291844</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.242938</td>\n",
       "      <td>0.315018</td>\n",
       "      <td>0.274322</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.534855</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.603951</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.685484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.375790</td>\n",
       "      <td>0.344470</td>\n",
       "      <td>0.332353</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.590881</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.621497</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.956044</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.360348</td>\n",
       "      <td>0.348614</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.630759</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.648593</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.593496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.268018</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.522694</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.555812</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "N              0.142857  0.058824  0.083333   17.000000\n",
       "NR             0.740741  0.219780  0.338983   91.000000\n",
       "R              0.144444  0.812500  0.245283   16.000000\n",
       "accuracy       0.274194  0.274194  0.274194    0.274194\n",
       "macro avg      0.342681  0.363701  0.222533  124.000000\n",
       "weighted avg   0.581831  0.274194  0.291844  124.000000\n",
       "N              0.000000  0.000000  0.000000   17.000000\n",
       "NR             0.728814  0.945055  0.822967   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.693548  0.693548  0.693548    0.693548\n",
       "macro avg      0.242938  0.315018  0.274322  124.000000\n",
       "weighted avg   0.534855  0.693548  0.603951  124.000000\n",
       "N              0.142857  0.058824  0.083333   17.000000\n",
       "NR             0.734513  0.912088  0.813725   91.000000\n",
       "R              0.250000  0.062500  0.100000   16.000000\n",
       "accuracy       0.685484  0.685484  0.685484    0.685484\n",
       "macro avg      0.375790  0.344470  0.332353  124.000000\n",
       "weighted avg   0.590881  0.685484  0.621497  124.000000\n",
       "N              0.250000  0.062500  0.100000   16.000000\n",
       "NR             0.750000  0.956044  0.840580   91.000000\n",
       "R              0.333333  0.062500  0.105263   16.000000\n",
       "accuracy       0.723577  0.723577  0.723577    0.723577\n",
       "macro avg      0.444444  0.360348  0.348614  123.000000\n",
       "weighted avg   0.630759  0.723577  0.648593  123.000000\n",
       "N              0.047619  0.062500  0.054054   16.000000\n",
       "NR             0.705882  0.800000  0.750000   90.000000\n",
       "R              0.000000  0.000000  0.000000   17.000000\n",
       "accuracy       0.593496  0.593496  0.593496    0.593496\n",
       "macro avg      0.251167  0.287500  0.268018  123.000000\n",
       "weighted avg   0.522694  0.593496  0.555812  123.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_adb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808056f",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b92512",
   "metadata": {},
   "source": [
    "### Model training and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f839c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = []\n",
    "estimator.append(('DTC', DecisionTreeClassifier()))\n",
    "estimator.append(('SVC', svm.SVC(kernel='linear', gamma = 'auto', probability = True)))\n",
    "estimator.append(('KNN', KNeighborsClassifier(n_neighbors=3)))\n",
    "kf5 = StratifiedKFold(n_splits = 5, shuffle=False)\n",
    "model3=AdaBoostClassifier(n_estimators=300, learning_rate=1.0)\n",
    "i=1\n",
    "dfs_vc = []\n",
    "for train_index, test_index in kf5.split(X3,y):\n",
    "    #select train and test datasets from X and y\n",
    "    X_train, X_test = X3.iloc[train_index], X3.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    #train the model\n",
    "    vc = VotingClassifier(estimators = estimator, voting='hard').fit(X_train, y_train)\n",
    "    #predict the test dataset\n",
    "    predicted3 = vc.predict(X_test)\n",
    "    #print the classification score report\n",
    "    report = classification_report(y_test, predicted3, output_dict = True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    dfs_vc.append(df)\n",
    "    i+=1\n",
    "results_df_vc = pd.concat(dfs_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d98a657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.131148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.540323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.283179</td>\n",
       "      <td>0.293256</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.545610</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.542428</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.556452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.375761</td>\n",
       "      <td>0.385208</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.591442</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.572169</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.552846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.360714</td>\n",
       "      <td>0.352106</td>\n",
       "      <td>0.351686</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.613328</td>\n",
       "      <td>0.552846</td>\n",
       "      <td>0.579406</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.723577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.647863</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>0.348976</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.708318</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.642804</td>\n",
       "      <td>123.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "N              0.000000  0.000000  0.000000   17.000000\n",
       "NR             0.000000  0.000000  0.000000   91.000000\n",
       "R              0.131148  1.000000  0.231884   16.000000\n",
       "accuracy       0.129032  0.129032  0.129032    0.129032\n",
       "macro avg      0.043716  0.333333  0.077295  124.000000\n",
       "weighted avg   0.016922  0.129032  0.029921  124.000000\n",
       "N              0.130435  0.176471  0.150000   17.000000\n",
       "NR             0.719101  0.703297  0.711111   91.000000\n",
       "R              0.000000  0.000000  0.000000   16.000000\n",
       "accuracy       0.540323  0.540323  0.540323    0.540323\n",
       "macro avg      0.283179  0.293256  0.287037  124.000000\n",
       "weighted avg   0.545610  0.540323  0.542428  124.000000\n",
       "N              0.181818  0.235294  0.205128   17.000000\n",
       "NR             0.734940  0.670330  0.701149   91.000000\n",
       "R              0.210526  0.250000  0.228571   16.000000\n",
       "accuracy       0.556452  0.556452  0.556452    0.556452\n",
       "macro avg      0.375761  0.385208  0.378283  124.000000\n",
       "weighted avg   0.591442  0.556452  0.572169  124.000000\n",
       "N              0.107143  0.187500  0.136364   16.000000\n",
       "NR             0.775000  0.681319  0.725146   91.000000\n",
       "R              0.200000  0.187500  0.193548   16.000000\n",
       "accuracy       0.552846  0.552846  0.552846    0.552846\n",
       "macro avg      0.360714  0.352106  0.351686  123.000000\n",
       "weighted avg   0.613328  0.552846  0.579406  123.000000\n",
       "N              0.200000  0.062500  0.095238   16.000000\n",
       "NR             0.743590  0.966667  0.840580   90.000000\n",
       "R              1.000000  0.058824  0.111111   17.000000\n",
       "accuracy       0.723577  0.723577  0.723577    0.723577\n",
       "macro avg      0.647863  0.362663  0.348976  123.000000\n",
       "weighted avg   0.708318  0.723577  0.642804  123.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4803df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
